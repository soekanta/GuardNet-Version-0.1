{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [],
            "toc_visible": true
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "language_info": {
            "name": "python"
        }
    },
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# üõ°Ô∏è GuardNet - Random Forest Training untuk Hybrid Detection\n",
                "\n",
                "Notebook ini digunakan untuk melatih model Random Forest yang ringan untuk sistem deteksi phishing hybrid di ekstensi Chrome GuardNet.\n",
                "\n",
                "## Alur Kerja:\n",
                "1. Upload dataset `PhiUSIIL_Phishing_URL_Dataset.csv`\n",
                "2. Preprocessing dan normalisasi fitur\n",
                "3. Training Random Forest dengan hyperparameter yang optimal untuk browser\n",
                "4. Export model ke format JSON untuk JavaScript\n",
                "5. Download file `rf_model.json`\n",
                "\n",
                "---"
            ],
            "metadata": {
                "id": "intro"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "## üì¶ Step 1: Install Dependencies & Import Libraries"
            ],
            "metadata": {
                "id": "step1"
            }
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "imports"
            },
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import json\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from google.colab import files\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "print(\"‚úÖ Libraries imported successfully!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "source": [
                "## üì§ Step 2: Upload Dataset\n",
                "\n",
                "Upload file `PhiUSIIL_Phishing_URL_Dataset.csv` dari folder `code/` di proyek GuardNet."
            ],
            "metadata": {
                "id": "step2"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Upload dataset\n",
                "print(\"üìÇ Please upload the dataset file (PhiUSIIL_Phishing_URL_Dataset.csv)...\")\n",
                "uploaded = files.upload()\n",
                "\n",
                "# Get the filename\n",
                "filename = list(uploaded.keys())[0]\n",
                "print(f\"\\n‚úÖ File uploaded: {filename}\")"
            ],
            "metadata": {
                "id": "upload"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Load dataset\n",
                "df = pd.read_csv(filename)\n",
                "print(f\"üìä Dataset shape: {df.shape}\")\n",
                "print(f\"\\nüìã Columns ({len(df.columns)} total):\")\n",
                "print(df.columns.tolist())\n",
                "print(f\"\\nüîç First 3 rows:\")\n",
                "df.head(3)"
            ],
            "metadata": {
                "id": "load_data"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## üîß Step 3: Data Preprocessing"
            ],
            "metadata": {
                "id": "step3"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Define the 50 features that match sandbox.js extraction\n",
                "FEATURE_NAMES = [\n",
                "    'URLLength', 'DomainLength', 'IsDomainIP', 'URLSimilarityIndex',\n",
                "    'CharContinuationRate', 'TLDLegitimateProb', 'URLCharProb', 'TLDLength',\n",
                "    'NoOfSubDomain', 'HasObfuscation', 'NoOfObfuscatedChar', 'ObfuscationRatio',\n",
                "    'NoOfLettersInURL', 'LetterRatioInURL', 'NoOfDigitsInURL', 'DigitRatioInURL',\n",
                "    'NoOfEqualsInURL', 'NoOfQMarkInURL', 'NoOfAmpersandInURL', 'NoOfOtherSpecialCharsInURL',\n",
                "    'SpacialCharRatioInURL', 'IsHTTPS', 'LineOfCode', 'LargestLineLength',\n",
                "    'HasTitle', 'DomainTitleMatchScore', 'URLTitleMatchScore', 'HasFavicon',\n",
                "    'Robots', 'IsResponsive', 'NoOfURLRedirect', 'NoOfSelfRedirect',\n",
                "    'HasDescription', 'NoOfPopup', 'NoOfiFrame', 'HasExternalFormSubmit',\n",
                "    'HasSocialNet', 'HasSubmitButton', 'HasHiddenFields', 'HasPasswordField',\n",
                "    'Bank', 'Pay', 'Crypto', 'HasCopyrightInfo',\n",
                "    'NoOfImage', 'NoOfCSS', 'NoOfJS', 'NoOfSelfRef', 'NoOfEmptyRef', 'NoOfExternalRef'\n",
                "]\n",
                "\n",
                "# Check which features exist in the dataset\n",
                "available_features = [f for f in FEATURE_NAMES if f in df.columns]\n",
                "missing_features = [f for f in FEATURE_NAMES if f not in df.columns]\n",
                "\n",
                "print(f\"‚úÖ Available features: {len(available_features)}/{len(FEATURE_NAMES)}\")\n",
                "if missing_features:\n",
                "    print(f\"‚ö†Ô∏è Missing features: {missing_features}\")"
            ],
            "metadata": {
                "id": "features"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Prepare features and target\n",
                "# Use available features, fill missing with 0\n",
                "X = pd.DataFrame()\n",
                "for feat in FEATURE_NAMES:\n",
                "    if feat in df.columns:\n",
                "        X[feat] = df[feat]\n",
                "    else:\n",
                "        X[feat] = 0  # Default value for missing features\n",
                "\n",
                "# Target variable - adjust column name as needed\n",
                "target_col = None\n",
                "for col in ['label', 'Label', 'phishing', 'Phishing', 'is_phishing', 'class', 'Class']:\n",
                "    if col in df.columns:\n",
                "        target_col = col\n",
                "        break\n",
                "\n",
                "if target_col is None:\n",
                "    print(\"‚ùå Target column not found! Available columns:\")\n",
                "    print(df.columns.tolist())\n",
                "else:\n",
                "    y = df[target_col]\n",
                "    print(f\"‚úÖ Target column: '{target_col}'\")\n",
                "    print(f\"\\nüìä Class distribution:\")\n",
                "    print(y.value_counts())"
            ],
            "metadata": {
                "id": "prepare_data"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Handle missing values\n",
                "X = X.fillna(0)\n",
                "\n",
                "# Convert any non-numeric to numeric\n",
                "for col in X.columns:\n",
                "    X[col] = pd.to_numeric(X[col], errors='coerce').fillna(0)\n",
                "\n",
                "print(f\"‚úÖ Features prepared: {X.shape}\")\n",
                "print(f\"\\nüìä Feature statistics:\")\n",
                "X.describe().T.head(10)"
            ],
            "metadata": {
                "id": "clean_data"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## üéØ Step 4: Train Random Forest Model\n",
                "\n",
                "Hyperparameters dioptimalkan untuk ukuran kecil dan performa browser:\n",
                "- `n_estimators=10` - Jumlah trees yang sedikit untuk ukuran file kecil\n",
                "- `max_depth=5` - Kedalaman dangkal untuk mencegah overfitting\n",
                "- `min_samples_leaf=20` - Hindari leaf node yang terlalu kecil"
            ],
            "metadata": {
                "id": "step4"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Split data\n",
                "X_train, X_test, y_train, y_test = train_test_split(\n",
                "    X, y, test_size=0.2, random_state=42, stratify=y\n",
                ")\n",
                "\n",
                "print(f\"üìä Training set: {X_train.shape[0]} samples\")\n",
                "print(f\"üìä Test set: {X_test.shape[0]} samples\")"
            ],
            "metadata": {
                "id": "split"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Train Random Forest with browser-optimized hyperparameters\n",
                "rf_model = RandomForestClassifier(\n",
                "    n_estimators=10,        # Sedikit trees untuk ukuran kecil\n",
                "    max_depth=5,            # Kedalaman dangkal\n",
                "    min_samples_leaf=20,    # Hindari leaf node kecil\n",
                "    min_samples_split=40,   # Minimum samples untuk split\n",
                "    random_state=42,\n",
                "    n_jobs=-1               # Gunakan semua CPU cores\n",
                ")\n",
                "\n",
                "print(\"üöÄ Training Random Forest...\")\n",
                "rf_model.fit(X_train, y_train)\n",
                "print(\"‚úÖ Training complete!\")"
            ],
            "metadata": {
                "id": "train"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Evaluate model\n",
                "y_pred = rf_model.predict(X_test)\n",
                "y_pred_proba = rf_model.predict_proba(X_test)\n",
                "\n",
                "print(\"üìä Model Evaluation:\")\n",
                "print(\"=\" * 50)\n",
                "print(f\"\\n‚úÖ Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
                "print(f\"\\nüìã Classification Report:\")\n",
                "print(classification_report(y_test, y_pred))\n",
                "print(f\"\\nüî¢ Confusion Matrix:\")\n",
                "print(confusion_matrix(y_test, y_pred))"
            ],
            "metadata": {
                "id": "evaluate"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Feature importance\n",
                "feature_importance = pd.DataFrame({\n",
                "    'feature': FEATURE_NAMES,\n",
                "    'importance': rf_model.feature_importances_\n",
                "}).sort_values('importance', ascending=False)\n",
                "\n",
                "print(\"üèÜ Top 15 Most Important Features:\")\n",
                "print(\"=\" * 50)\n",
                "for i, row in feature_importance.head(15).iterrows():\n",
                "    bar = \"‚ñà\" * int(row['importance'] * 50)\n",
                "    print(f\"{row['feature']:25s} {row['importance']:.4f} {bar}\")"
            ],
            "metadata": {
                "id": "importance"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## üì¶ Step 5: Export Model to JSON\n",
                "\n",
                "Konversi Random Forest sklearn ke format JSON yang bisa dibaca oleh JavaScript di browser."
            ],
            "metadata": {
                "id": "step5"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "def tree_to_json(tree, feature_names):\n",
                "    \"\"\"\n",
                "    Convert sklearn DecisionTree to JSON format for JavaScript.\n",
                "    \"\"\"\n",
                "    tree_ = tree.tree_\n",
                "    feature_name = feature_names\n",
                "\n",
                "    def recurse(node):\n",
                "        if tree_.feature[node] != -2:  # Not a leaf node\n",
                "            feature_index = int(tree_.feature[node])\n",
                "            threshold = float(tree_.threshold[node])\n",
                "            left_child = int(tree_.children_left[node])\n",
                "            right_child = int(tree_.children_right[node])\n",
                "\n",
                "            return {\n",
                "                \"featureIndex\": feature_index,\n",
                "                \"threshold\": round(threshold, 4),\n",
                "                \"left\": recurse(left_child),\n",
                "                \"right\": recurse(right_child)\n",
                "            }\n",
                "        else:  # Leaf node\n",
                "            # Get class probabilities\n",
                "            value = tree_.value[node][0]\n",
                "            total = sum(value)\n",
                "            probs = [round(v / total, 4) for v in value]\n",
                "            return {\"value\": probs}\n",
                "\n",
                "    return recurse(0)\n",
                "\n",
                "\n",
                "def export_rf_to_json(rf_model, feature_names, output_path='rf_model.json'):\n",
                "    \"\"\"\n",
                "    Export Random Forest model to JSON format for JavaScript.\n",
                "    \"\"\"\n",
                "    trees_json = []\n",
                "    for i, tree in enumerate(rf_model.estimators_):\n",
                "        tree_json = tree_to_json(tree, feature_names)\n",
                "        trees_json.append(tree_json)\n",
                "        print(f\"  Tree {i+1}/{len(rf_model.estimators_)} exported\")\n",
                "\n",
                "    model_json = {\n",
                "        \"model_info\": {\n",
                "            \"name\": \"GuardNet Random Forest\",\n",
                "            \"version\": \"1.0.0\",\n",
                "            \"description\": \"Random Forest for phishing detection - trained on PhiUSIIL dataset\",\n",
                "            \"n_estimators\": len(rf_model.estimators_),\n",
                "            \"max_depth\": rf_model.max_depth,\n",
                "            \"accuracy\": round(accuracy_score(y_test, y_pred), 4),\n",
                "            \"trained_on\": \"PhiUSIIL_Phishing_URL_Dataset\"\n",
                "        },\n",
                "        \"feature_names\": feature_names,\n",
                "        \"n_estimators\": len(rf_model.estimators_),\n",
                "        \"max_depth\": rf_model.max_depth,\n",
                "        \"trees\": trees_json\n",
                "    }\n",
                "\n",
                "    with open(output_path, 'w') as f:\n",
                "        json.dump(model_json, f, indent=2)\n",
                "\n",
                "    # Calculate file size\n",
                "    import os\n",
                "    file_size = os.path.getsize(output_path) / 1024\n",
                "\n",
                "    return output_path, file_size\n",
                "\n",
                "\n",
                "print(\"üì¶ Exporting Random Forest to JSON...\")\n",
                "output_path, file_size = export_rf_to_json(rf_model, FEATURE_NAMES)\n",
                "print(f\"\\n‚úÖ Model exported to: {output_path}\")\n",
                "print(f\"üìÅ File size: {file_size:.2f} KB\")"
            ],
            "metadata": {
                "id": "export"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Verify the exported JSON\n",
                "with open('rf_model.json', 'r') as f:\n",
                "    exported_model = json.load(f)\n",
                "\n",
                "print(\"üìã Exported Model Structure:\")\n",
                "print(\"=\" * 50)\n",
                "print(f\"  n_estimators: {exported_model['n_estimators']}\")\n",
                "print(f\"  max_depth: {exported_model['max_depth']}\")\n",
                "print(f\"  features: {len(exported_model['feature_names'])}\")\n",
                "print(f\"  trees: {len(exported_model['trees'])}\")\n",
                "print(f\"\\nüìä Model Info:\")\n",
                "for key, value in exported_model['model_info'].items():\n",
                "    print(f\"  {key}: {value}\")"
            ],
            "metadata": {
                "id": "verify"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## üì• Step 6: Download Model File\n",
                "\n",
                "Download file `rf_model.json` dan letakkan di folder `models/` di proyek GuardNet."
            ],
            "metadata": {
                "id": "step6"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Download the model file\n",
                "print(\"üì• Downloading rf_model.json...\")\n",
                "files.download('rf_model.json')\n",
                "print(\"\\n‚úÖ Download complete!\")\n",
                "print(\"\\nüìù Next steps:\")\n",
                "print(\"  1. Letakkan file rf_model.json di folder: GuardNet Test 1.2/models/\")\n",
                "print(\"  2. Replace file rf_model.json yang sudah ada (placeholder)\")\n",
                "print(\"  3. Reload extension di Chrome\")\n",
                "print(\"  4. Test dengan URL phishing dan legitimate\")"
            ],
            "metadata": {
                "id": "download"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "---\n",
                "\n",
                "## üéâ Selesai!\n",
                "\n",
                "Model Random Forest sudah diekspor ke `rf_model.json`. File ini akan digunakan oleh JavaScript classifier di ekstensi GuardNet untuk hybrid detection bersama dengan model Logistic Regression.\n",
                "\n",
                "### Struktur File Model:\n",
                "```\n",
                "models/\n",
                "‚îú‚îÄ‚îÄ model.json           # TensorFlow.js (Logistic Regression)\n",
                "‚îú‚îÄ‚îÄ scaler_params.json   # StandardScaler parameters\n",
                "‚îú‚îÄ‚îÄ rf_model.json        # Random Forest (dari notebook ini)\n",
                "‚îî‚îÄ‚îÄ group1-shard1of1.bin # TF.js weights\n",
                "```"
            ],
            "metadata": {
                "id": "done"
            }
        }
    ]
}